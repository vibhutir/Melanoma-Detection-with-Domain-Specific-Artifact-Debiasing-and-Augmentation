{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Hair Augmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vibhutir/Melanoma-Detection-with-Domain-Specific-Artifact-Debiasing-and-Augmentation/blob/main/Copy_of_Hair_Augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "BKyuL8s09TVK",
        "outputId": "5a4a5183-234a-4c9a-c187-4c60cccbc834",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import albumentations as albu\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "PVDzd_c-fVIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hair_pic = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "ceLUm4upefH7",
        "outputId": "c2e85a7f-2424-4216-b2b6-26936219cc9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-42b5697fc0c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhair_pic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'files' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "no_hair_pic = files.upload()"
      ],
      "metadata": {
        "id": "etGcS7JufOtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size=1024\n",
        "\n",
        "hair = cv2.imread('ISIC_0000019_downsampled (1).jpg')\n",
        "image_resize_hair = cv2.resize(hair,(size,size))\n",
        "    \n",
        "image_resize_hair = cv2.cvtColor(image_resize_hair,cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(image_resize_hair)"
      ],
      "metadata": {
        "id": "JTApthDbgsfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size=1024\n",
        "\n",
        "no_hair = cv2.imread('ISIC_0000008 (1).jpg')\n",
        "image_resize_no_hair = cv2.resize(no_hair,(size,size))\n",
        "    \n",
        "image_resize_no_hair = cv2.cvtColor(image_resize_no_hair,cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(image_resize_no_hair)"
      ],
      "metadata": {
        "id": "2JGwoLcYijoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting hair mask from hairy image\n",
        "lower_limit = 20 # the value that I found helpful\n",
        "\n",
        "#*********#*********PROCEDURE*********#*********#*********#\n",
        "###################################\n",
        "grayScale = cv2.cvtColor(image_resize_hair, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "# Kernel for the    \n",
        "kernel = cv2.getStructuringElement(1,(17,17))\n",
        "\n",
        "# Perform the blackHat filtering on the grayscale image to find the hair countours\n",
        "blackhat = cv2.morphologyEx(grayScale, cv2.MORPH_BLACKHAT, kernel)\n",
        "\n",
        "# intensify the hair countours  \n",
        "_ ,threshold = cv2.threshold(blackhat,20,255,cv2.THRESH_BINARY)\n",
        "#######################################\n",
        "threshold = cv2.bitwise_not(threshold)\n",
        "plt.imshow(threshold,cmap = 'gray')\n"
      ],
      "metadata": {
        "id": "jfxJwRr8i8fA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('no hair image with hair mask on it')\n",
        "plt.imshow(cv2.bitwise_and(image_resize_no_hair,image_resize_no_hair,mask = threshold))"
      ],
      "metadata": {
        "id": "JguGvGVLjZQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell to mount Google Drive for Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "# !ls '/content/drive/My Drive/Colab Notebooks'\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/Shareddrives/Colab Notebooks/isic-2019')"
      ],
      "metadata": {
        "id": "VZbKdFAd2NUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -u \"/content/drive/My Drive/Colab Notebooks/isic-2019/ISIC_2019_Training_Input.zip\" -d \"/content/drive/My Drive/Colab Notebooks/isic-2019/ISIC_2019_Training_Input\""
      ],
      "metadata": {
        "id": "4vvIOCXj96z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_PATH = '/content/drive/My Drive/Colab Notebooks/isic-2019/ISIC_2019_Training_Input/ISIC_2019_Training_Input'\n",
        "#list of images with hair\n",
        "#hair_images =['ISIC_0078712','ISIC_0080817','ISIC_0082348','ISIC_0109869','ISIC_0155012','ISIC_0159568','ISIC_0164145','ISIC_0194550','ISIC_0194914','ISIC_0202023','ISIC_0083035','ISIC_0068279','ISIC_0109703','ISIC_0149527']\n",
        "hair_images = ['ISIC_0030107', 'ISIC_0030169','ISIC_0030167','ISIC_0030218','ISIC_0030234','ISIC_0030132','ISIC_0030127','ISIC_0030120','ISIC_0030097','ISIC_0030072','ISIC_0030167','ISIC_0031222','ISIC_0031180','ISIC_0030524']"
      ],
      "metadata": {
        "id": "tyHMTolABYZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size=1024\n",
        "for img in hair_images:\n",
        "    image = cv2.imread(BASE_PATH + '/' + img + '.jpg')\n",
        "    image_resize = cv2.resize(image,(size,size))\n",
        "    image_resize = cv2.cvtColor(image_resize,cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(image_resize)\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "5tyqM7gWBq8M",
        "outputId": "f6bd8041-ca92-4649-a437-6de6083c3d85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-b31635f94305>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhair_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mimage_resize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mimage_resize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_resize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_resize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting hair masks from images\n",
        "def img(image_name,lower_limit=20):    \n",
        "    '''\n",
        "    Helper Function to help us iterate with our code!!   \n",
        "    \n",
        "    \n",
        "    '''\n",
        "\n",
        "    image = cv2.imread(BASE_PATH + '/' + image_name + '.jpg')\n",
        "    image_resize = cv2.resize(image,(size,size))\n",
        "   \n",
        "    grayScale = cv2.cvtColor(image_resize, cv2.COLOR_RGB2GRAY)\n",
        "      # Kernel for the morphological filtering\n",
        "    kernel = cv2.getStructuringElement(1,(17,17))\n",
        "\n",
        "    # Perform the blackHat filtering on the grayscale image to find the hair countours\n",
        "    blackhat = cv2.morphologyEx(grayScale, cv2.MORPH_BLACKHAT, kernel)\n",
        "\n",
        "    # intensify the hair countours in preparation for the inpainting \n",
        "    _ ,threshold = cv2.threshold(blackhat,lower_limit,255,cv2.THRESH_BINARY)\n",
        "    # inpaint the original image depending on the mask\n",
        "    final_image = cv2.inpaint(image_resize,threshold,1,cv2.INPAINT_TELEA)\n",
        "    \n",
        "    threshold = cv2.bitwise_not(threshold)\n",
        "    image_resize = cv2.cvtColor(image_resize,cv2.COLOR_BGR2RGB)\n",
        "    final_image = cv2.cvtColor(final_image,cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    return image_resize,threshold,final_image"
      ],
      "metadata": {
        "id": "CJ0Ps5r8EwIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_2,hair_mask_2,_ = img(hair_images[1])\n",
        "plt.title('The second image')\n",
        "plt.imshow(image_2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aL1EIMRmFpVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('The hair mask of the second image')\n",
        "plt.imshow(hair_mask_2,cmap = 'binary_r')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mtS5MTrMGJuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_1,_,_ = img(hair_images[0]) \n",
        "plt.title('The second image')\n",
        "plt.imshow(image_1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2Ng6QVsTGaei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,img_name in enumerate(hair_images) :\n",
        "    _,hair_mask,_ = img(img_name)\n",
        "    plt.title(f'{i},{img_name}')\n",
        "    plt.imshow(cv2.bitwise_and(image_1,image_1,mask = hair_mask))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "UQ4LrhlpGdkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "possible_cands = [0,1,2,3,4,5,6,7,8,9,10,11,12,13]# possible candidates \n",
        "all_hair_masks = []\n",
        "for i,img_id in enumerate(possible_cands):\n",
        "    _,hair_masks,_ = img(hair_images[img_id])\n",
        "    all_hair_masks.append(hair_masks) \n",
        "    cv2.imwrite(f'image_{i}.jpg',hair_masks)\n",
        "    print(len(all_hair_masks))"
      ],
      "metadata": {
        "id": "0YOlaPAFG0Gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_hair_masks = np.array(all_hair_masks)\n",
        "np.save('hair_array.npy',all_hair_masks.astype(np.uint8))\n"
      ],
      "metadata": {
        "id": "hnQq1rcJHLwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the hairs\n",
        "hairs = np.load('hair_array.npy')\n",
        "#the random transformations we want to apply on the masks\n",
        "hair_trans = albu.Compose([\n",
        "    albu.ShiftScaleRotate(rotate_limit=[-45,45],scale_limit=[-0.1,0.1],\n",
        "                          shift_limit=[-0.1,0.15],border_mode=3,p=1.)])"
      ],
      "metadata": {
        "id": "EJzm90-wHlPh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "07d723fc-3b8f-41de-dcca-5da852ca7661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-b1541e149c7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#loading the hairs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hair_array.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#the random transformations we want to apply on the masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m hair_trans = albu.Compose([\n\u001b[1;32m      5\u001b[0m     albu.ShiftScaleRotate(rotate_limit=[-45,45],scale_limit=[-0.1,0.1],\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'hair_array.npy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import choice\n",
        "def hair_mask(hairs,IMAGE_SIZE,p = 0.3):\n",
        "    chance = np.random.uniform(0,1,1)\n",
        "    if chance <= p:\n",
        "        mask_to_chose = choice(np.arange(14), 1,p=[0.07,0.07,0.07,0.07,0.07,0.07,0.07,0.07,0.07,0.07,0.075,0.075,0.075,0.075])[0]\n",
        "        mask = hairs[mask_to_chose]\n",
        "        \n",
        "        mask = hair_trans(image = mask)['image']\n",
        "        mask = cv2.resize(mask/255,(IMAGE_SIZE,IMAGE_SIZE),cv2.INTER_CUBIC)\n",
        "        mask[mask == 1.] =  255\n",
        "        mask[mask != 255.] = 0\n",
        "    else:\n",
        "        mask = np.ones((IMAGE_SIZE,IMAGE_SIZE))\n",
        "    return mask"
      ],
      "metadata": {
        "id": "bouXtG9jJFMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "msk = hair_mask(hairs,IMAGE_SIZE=256,p=1.).astype(np.uint8)\n",
        "plt.imshow(msk,cmap = 'binary_r')"
      ],
      "metadata": {
        "id": "GwiAKovoJV0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = no_hair\n",
        "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "img = cv2.resize(img,(256,256))\n",
        "\n",
        "plt.imshow(cv2.bitwise_and(img,img,mask= msk))"
      ],
      "metadata": {
        "id": "PtPUEvzcJaRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use this in data loader!!\n",
        "#composition = albu.Compose([albu.ShiftScaleRotate(rotate_limit=[-90,90],scale_limit=[-0.42,0.35],shift_limit=0,border_mode=0,p=0.5),])\n",
        "#image = composition(image=img)['image']\n",
        "#msk = hair_mask(hairs,IMAGE_SIZE=256,p=1.).astype(np.uint8)\n",
        "#image = cv2.bitwise_and(img,img,mask= msk)"
      ],
      "metadata": {
        "id": "FjZFFBByJwSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EdjL56IEeNlf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}